{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ad6fddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 1. Imports & NLTK stopwords\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords', quiet=True)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gradio as gr\n",
    "from fuzzywuzzy import process, fuzz\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c314f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets loaded.\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 2. Load datasets\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "tmdb_movies  = pd.read_csv('tmdb_5000_movies.csv')\n",
    "tmdb_credits = pd.read_csv('tmdb_5000_credits.csv')\n",
    "ml_movies    = pd.read_csv('movies.csv')      # title, genres, movieId\n",
    "ml_ratings   = pd.read_csv('ratings.csv')    # userId, movieId, rating\n",
    "\n",
    "print(\"Datasets loaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de9007ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MovieLens avg ratings sample:\n",
      "                                title  avg_rating  count\n",
      "0                    Toy Story (1995)        3.92  49695\n",
      "1                      Jumanji (1995)        3.21  22243\n",
      "2             Grumpier Old Men (1995)        3.15  12735\n",
      "3            Waiting to Exhale (1995)        2.86   2756\n",
      "4  Father of the Bride Part II (1995)        3.06  12161\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# BLOCK 3 – AVERAGE RATING + COUNT (NO MORE KeyError)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "# Compute BOTH mean AND count per movie\n",
    "avg_stats = (\n",
    "    ml_ratings.groupby('movieId')['rating']\n",
    "              .agg(['mean', 'count'])  # <-- BOTH\n",
    "              .reset_index()\n",
    ")\n",
    "\n",
    "# Rename mean → avg_rating\n",
    "avg_stats = avg_stats.rename(columns={'mean': 'avg_rating'})\n",
    "\n",
    "# Round for readability\n",
    "avg_stats['avg_rating'] = avg_stats['avg_rating'].round(2)\n",
    "\n",
    "# Merge with ml_movies\n",
    "ml_movies = ml_movies.merge(avg_stats, on='movieId', how='left')\n",
    "\n",
    "# Fill missing ratings (cold-start movies)\n",
    "ml_movies['avg_rating'] = ml_movies['avg_rating'].fillna(3.0)\n",
    "ml_movies['count'] = ml_movies['count'].fillna(0).astype(int)\n",
    "\n",
    "print(\"MovieLens avg ratings sample:\")\n",
    "print(ml_movies[['title', 'avg_rating', 'count']].head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c19e0c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cached merged data from merged_movies_cache.pkl...\n",
      "Loaded 3736 movies from cache!\n",
      "\n",
      "Final merged shape: (3736, 24)\n",
      "Columns: ['budget', 'genres', 'homepage', 'id', 'keywords', 'original_language', 'original_title', 'overview', 'popularity', 'production_companies', 'production_countries', 'release_date', 'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title', 'vote_average', 'vote_count', 'title_clean', 'genres_ml', 'avg_rating_ml', 'rating_count']\n",
      "\n",
      "Sample data:\n",
      "                                      title  avg_rating_ml  rating_count\n",
      "0                                    Avatar           3.78          9753\n",
      "1  Pirates of the Caribbean: At World's End           3.39          5428\n",
      "2                     The Dark Knight Rises           4.00          4770\n",
      "3                               John Carter           3.28           625\n",
      "4                              Spider-Man 3           3.01          4256\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# OPTIMIZED BLOCK 4 – FUZZY MERGE WITH CACHING\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# File to cache the merged dataframe\n",
    "CACHE_FILE = 'merged_movies_cache.pkl'\n",
    "\n",
    "def clean_title(t):\n",
    "    t = re.sub(r'\\s*\\(\\d{4}\\)', '', t)\n",
    "    t = re.sub(r'^(the|a|an)\\s+', '', t, flags=re.IGNORECASE)\n",
    "    return t.strip().lower()\n",
    "\n",
    "# Check if cached version exists\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    print(f\"Loading cached merged data from {CACHE_FILE}...\")\n",
    "    with open(CACHE_FILE, 'rb') as f:\n",
    "        merged = pickle.load(f)\n",
    "    print(f\"Loaded {len(merged)} movies from cache!\")\n",
    "else:\n",
    "    print(\"No cache found. Running fuzzy merge (this will take time)...\")\n",
    "    \n",
    "    tmdb_movies['title_clean'] = tmdb_movies['title'].apply(clean_title)\n",
    "    ml_movies['title_clean'] = ml_movies['title'].apply(clean_title)\n",
    "    \n",
    "    # OPTIMIZATION 1: Build a dict for faster lookup\n",
    "    ml_titles_dict = dict(zip(ml_movies['title_clean'], ml_movies.index))\n",
    "    \n",
    "    matches = []\n",
    "    total = len(tmdb_movies)\n",
    "    \n",
    "    # OPTIMIZATION 2: Use tqdm for progress bar\n",
    "    try:\n",
    "        from tqdm import tqdm\n",
    "        iterator = tqdm(tmdb_movies['title_clean'], desc=\"Matching titles\")\n",
    "    except ImportError:\n",
    "        print(\"Install tqdm for progress bar: pip install tqdm\")\n",
    "        iterator = tmdb_movies['title_clean']\n",
    "    \n",
    "    for i, tmdb_title in enumerate(iterator):\n",
    "        # Print progress every 100 movies if no tqdm\n",
    "        if i % 100 == 0 and 'tqdm' not in str(type(iterator)):\n",
    "            print(f\"Progress: {i}/{total} ({i/total*100:.1f}%)\")\n",
    "        \n",
    "        # OPTIMIZATION 3: Limit comparison to 100 best candidates\n",
    "        best = process.extractOne(\n",
    "            tmdb_title, \n",
    "            ml_movies['title_clean'].tolist(),\n",
    "            scorer=fuzz.ratio,\n",
    "            score_cutoff=85  # Skip if score < 85\n",
    "        )\n",
    "        \n",
    "        if best:\n",
    "            ml_idx = ml_movies[ml_movies['title_clean'] == best[0]].index[0]\n",
    "            tmdb_idx = tmdb_movies[tmdb_movies['title_clean'] == tmdb_title].index[0]\n",
    "            matches.append((tmdb_idx, ml_idx))\n",
    "    \n",
    "    print(f\"\\nFound {len(matches)} matches!\")\n",
    "    \n",
    "    if matches:\n",
    "        # Extract TMDB and MovieLens parts\n",
    "        tmdb_part = tmdb_movies.iloc[[m[0] for m in matches]].reset_index(drop=True)\n",
    "        ml_part = ml_movies.iloc[[m[1] for m in matches]][['genres', 'avg_rating', 'count']].reset_index(drop=True)\n",
    "        \n",
    "        # Rename MovieLens columns to avoid conflict\n",
    "        ml_part = ml_part.rename(columns={\n",
    "            'genres': 'genres_ml',\n",
    "            'avg_rating': 'avg_rating_ml',\n",
    "            'count': 'rating_count'\n",
    "        })\n",
    "        \n",
    "        # Concatenate\n",
    "        merged = pd.concat([tmdb_part, ml_part], axis=1)\n",
    "        print(f\"Merged {len(merged)} movies with REAL ratings!\")\n",
    "    else:\n",
    "        merged = tmdb_movies.copy()\n",
    "        merged['avg_rating_ml'] = 3.5\n",
    "        merged['rating_count'] = 0\n",
    "        merged['genres_ml'] = ''\n",
    "    \n",
    "    # SAVE TO CACHE\n",
    "    print(f\"Saving merged data to {CACHE_FILE}...\")\n",
    "    with open(CACHE_FILE, 'wb') as f:\n",
    "        pickle.dump(merged, f)\n",
    "    print(\"Cache saved! Next time this will load instantly.\")\n",
    "\n",
    "# Verify the data\n",
    "print(f\"\\nFinal merged shape: {merged.shape}\")\n",
    "print(f\"Columns: {list(merged.columns)}\")\n",
    "print(f\"\\nSample data:\")\n",
    "print(merged[['title', 'avg_rating_ml', 'rating_count']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a8aa286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 5. Extract genres, keywords, top-3 cast, director\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def safe_list(col, key='name'):\n",
    "    try:\n",
    "        return ' '.join([i[key].lower().replace(' ','') for i in ast.literal_eval(col)])\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "def get_director(crew):\n",
    "    try:\n",
    "        for p in ast.literal_eval(crew):\n",
    "            if p['job']=='Director':\n",
    "                return p['name'].lower().replace(' ','')\n",
    "        return ''\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "merged['genres_tmdb'] = merged['genres'].apply(lambda x: safe_list(x,'name'))\n",
    "merged['keywords']    = merged['keywords'].apply(lambda x: safe_list(x,'name'))\n",
    "merged['genres_ml']   = merged['genres_ml'].apply(lambda x: x.lower().replace('|',' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e377bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# 6. Remove stop-words from overview\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def clean_overview(txt):\n",
    "    if pd.isna(txt): return ''\n",
    "    return ' '.join([w.lower() for w in str(txt).split() if w.lower() not in stop_words])\n",
    "\n",
    "merged['overview'] = merged['overview'].apply(clean_overview)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe7fa96f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merged shape: (3736, 25)\n",
      "Any overview? 3736\n",
      "Sample overview: 22nd century, paraplegic marine dispatched moon pandora unique mission, becomes torn following orders protecting alien civilization.\n"
     ]
    }
   ],
   "source": [
    "print(\"merged shape:\", merged.shape)\n",
    "print(\"Any overview?\", merged['overview'].notna().sum())\n",
    "print(\"Sample overview:\", merged['overview'].iloc[0] if len(merged) > 0 else \"EMPTY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb0e4715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix ready: (3736, 1529)\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# BLOCK 7 – FEATURE MATRIX (USE avg_rating_ml)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, MinMaxScaler\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "# 1. Overview\n",
    "overview_text = merged['overview'].fillna('').replace('', 'plot unknown')\n",
    "tfidf_overview = TfidfVectorizer(max_features=1000, stop_words='english', min_df=1)\n",
    "overview_matrix = tfidf_overview.fit_transform(overview_text)\n",
    "\n",
    "# 2. Keywords\n",
    "keywords_text = merged['keywords'].fillna('').replace('', 'none')\n",
    "tfidf_keywords = TfidfVectorizer(max_features=500)\n",
    "keywords_matrix = tfidf_keywords.fit_transform(keywords_text)\n",
    "\n",
    "# 3. Genres (TMDB + ML combined)\n",
    "genre_list = (\n",
    "    merged['genres_tmdb'].fillna('').str.split() + \n",
    "    merged['genres_ml'].fillna('').str.split()\n",
    ")\n",
    "mlb_genre = MultiLabelBinarizer()\n",
    "genres_matrix = mlb_genre.fit_transform(genre_list)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 6. Rating boost (USE avg_rating_ml)\n",
    "scaler = MinMaxScaler()\n",
    "rating_boost = scaler.fit_transform(merged[['avg_rating_ml']])  # FIXED\n",
    "rating_boost = rating_boost * 2.0  # Strong boost\n",
    "\n",
    "# 7. Combine\n",
    "feature_matrix = hstack([\n",
    "    overview_matrix * 1.0,\n",
    "    keywords_matrix * 0.8,\n",
    "    csr_matrix(genres_matrix) * 1.2,\n",
    "    csr_matrix(rating_boost) * 1.5\n",
    "])\n",
    "\n",
    "print(f\"Feature matrix ready: {feature_matrix.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6bc7aa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices built: 3736 movies\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# BLOCK 8 – SIMILARITY + CORRECT INDICES\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "cosine_sim = cosine_similarity(feature_matrix, feature_matrix)\n",
    "\n",
    "# CORRECT: Map lowercase title → index\n",
    "indices = pd.Series(\n",
    "    merged.index,\n",
    "    index=merged['title'].str.lower().str.strip()\n",
    ").drop_duplicates()\n",
    "\n",
    "print(f\"Indices built: {len(indices)} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3b496be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# BLOCK 9 – RECOMMEND (FIXED)\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "def get_recommendations(title, top_n=5):\n",
    "    title = title.strip().lower()\n",
    "    \n",
    "    if title not in indices:\n",
    "        # Fuzzy fallback\n",
    "        matches = [idx for idx, t in indices.items() if title in t]\n",
    "        if not matches:\n",
    "            return f\"Movie '{title}' not found. Try 'avatar', 'titanic', or 'inception'.\"\n",
    "        idx = matches[0]\n",
    "    else:\n",
    "        idx = indices[title]\n",
    "    \n",
    "    sim_scores = sorted(enumerate(cosine_sim[idx]), key=lambda x: x[1], reverse=True)[1:top_n+1]\n",
    "    \n",
    "    recs = []\n",
    "    for i, score in sim_scores:\n",
    "        movie_title = merged.iloc[i]['title']\n",
    "        rating = merged.iloc[i].get('avg_rating', 3.0)\n",
    "        recs.append(f\"• **{movie_title}** (Rating: {rating:.1f})\")\n",
    "    \n",
    "    return f\"Recommendations for **{merged.iloc[idx]['title']}**:\\n\" + \"\\n\".join(recs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "55ff95b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\chat_interface.py:347: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  self.chatbot = Chatbot(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* Running on public URL: https://546c59aba1ad0ea081.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://546c59aba1ad0ea081.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\queueing.py\", line 759, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\route_utils.py\", line 354, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 2116, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\blocks.py\", line 1621, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\utils.py\", line 882, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\chat_interface.py\", line 553, in __wrapper\n",
      "    return await submit_fn(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\gradio\\chat_interface.py\", line 943, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2485, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\anyio\\_backends\\_asyncio.py\", line 976, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Temp\\ipykernel_30828\\2353880785.py\", line 48, in chatbot\n",
      "    idx = fuzzy_find_title(title_query)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\one\\AppData\\Local\\Temp\\ipykernel_30828\\2353880785.py\", line 31, in fuzzy_find_title\n",
      "    if fuzz.partial_ratio(partial, full_title.lower()) >= threshold:\n",
      "                                   ^^^^^^^^^^^^^^^^\n",
      "AttributeError: 'int' object has no attribute 'lower'\n"
     ]
    }
   ],
   "source": [
    "# ──────────────────────────────────────────────────────────────\n",
    "# ENHANCED CHATBOT: NATURAL LANGUAGE + FUZZY\n",
    "# ──────────────────────────────────────────────────────────────\n",
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def parse_query(message):\n",
    "    msg = message.lower().strip()\n",
    "    \n",
    "    # 1. Extract movie title (after \"like\", \"similar to\", etc.)\n",
    "    patterns = [\n",
    "        r'(?:like|similar to|recommend|show me)\\s+([^\\.!,?]+)',\n",
    "        r'^(?!.*\\b(action|comedy|drama|sci-fi|horror)\\b)(.+?)(?:\\s+movie|\\s+film)?$'\n",
    "    ]\n",
    "    title = None\n",
    "    for p in patterns:\n",
    "        match = re.search(p, msg)\n",
    "        if match:\n",
    "            title = match.group(1).strip()\n",
    "            break\n",
    "    \n",
    "    # 2. Detect genre\n",
    "    genres = ['action', 'comedy', 'drama', 'sci-fi', 'horror', 'romance', 'thriller']\n",
    "    detected_genre = next((g for g in genres if g in msg), None)\n",
    "    \n",
    "    return title, detected_genre\n",
    "\n",
    "def fuzzy_find_title(partial_title, threshold=70):\n",
    "    partial = partial_title.lower()\n",
    "    for idx, full_title in indices.items():\n",
    "        if fuzz.partial_ratio(partial, full_title.lower()) >= threshold:\n",
    "            return idx\n",
    "    return None\n",
    "\n",
    "def chatbot(message, history):\n",
    "    title_query, genre_query = parse_query(message)\n",
    "    \n",
    "    # CASE 1: Genre-only request\n",
    "    if genre_query and not title_query:\n",
    "        genre_movies = merged[merged['genres_tmdb'].str.contains(genre_query, case=False, na=False)]\n",
    "        if genre_movies.empty:\n",
    "            return f\"No {genre_query} movies found.\"\n",
    "        sample_title = genre_movies.iloc[0]['title']\n",
    "        return f\"Top {genre_query.title()} pick: **{sample_title}**\\n\\n\" + get_recommendations(sample_title)\n",
    "    \n",
    "    # CASE 2: Movie title (fuzzy)\n",
    "    if title_query:\n",
    "        idx = fuzzy_find_title(title_query)\n",
    "        if not idx:\n",
    "            return f\"Couldn't find '{title_query}'. Try 'Inception', 'Titanic', or 'Avatar'.\"\n",
    "        movie_title = merged.iloc[idx]['title']\n",
    "        return get_recommendations(movie_title)\n",
    "    \n",
    "    # CASE 3: Fallback\n",
    "    return \"Try: 'Movies like Inception', 'Recommend action', or 'Sci-fi like Matrix'\"\n",
    "\n",
    "# LAUNCH\n",
    "gr.ChatInterface(\n",
    "    chatbot,\n",
    "    title=\"Smart Movie Recommender\",\n",
    "    description=\"Say: 'Like Inception', 'Action movies', 'Sci-fi like Matrix'\",\n",
    "    examples=[\n",
    "        \"Movies like Inception\",\n",
    "        \"Recommend action movies\",\n",
    "        \"Sci-fi like The Matrix\",\n",
    "        \"Titanik\",\n",
    "        \"Incept\"\n",
    "    ],\n",
    "    theme=gr.themes.Soft()\n",
    ").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceecf9da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for **Titanic**:\n",
      "• **My Summer of Love** (Rating: 3.0)\n",
      "• **Cruel Intentions** (Rating: 3.0)\n",
      "• **Fatal Attraction** (Rating: 3.0)\n",
      "• **O** (Rating: 3.0)\n",
      "• **Angel Eyes** (Rating: 3.0)\n"
     ]
    }
   ],
   "source": [
    "print(get_recommendations(\"Titanic\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
